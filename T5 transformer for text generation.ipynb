{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T5 transformer for text generation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOoBbFWhd39bX/B7yCNir6r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0a62622aa6b9425c9192d7db9570c83a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_83e484770be345479cea6ed14e093348","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b7c00848532e47ae9deea1160d25b6bc","IPY_MODEL_13e3236cbe504ff0bc1298fca7369f0f"]}},"83e484770be345479cea6ed14e093348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7c00848532e47ae9deea1160d25b6bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_abfa126f7dd84b52a47af9aaf5c1df86","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":791656,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":791656,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff734318c8844d1bad3932f87b99fc5e"}},"13e3236cbe504ff0bc1298fca7369f0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5cac03a79918426d99e50af1278d6f06","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 792k/792k [02:40&lt;00:00, 4.93kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb16bdea950e4f56bcfe84afb5c30340"}},"abfa126f7dd84b52a47af9aaf5c1df86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ff734318c8844d1bad3932f87b99fc5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cac03a79918426d99e50af1278d6f06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bb16bdea950e4f56bcfe84afb5c30340":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"095a328a7f7246a2aee1a2a16ed7782b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cfd835ed937940659395e77055a24f2b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_551a29dba30245509623446ca4b98bbc","IPY_MODEL_7e29422a019f4670b654f3761ee3c484"]}},"cfd835ed937940659395e77055a24f2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"551a29dba30245509623446ca4b98bbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13b39845cd274e3b900d19c875adc8be","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1389353,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1389353,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_594a2886e4134b81af747527f97e8c6a"}},"7e29422a019f4670b654f3761ee3c484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b25094cbb91462a9bac17a230c314b5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.39M/1.39M [02:40&lt;00:00, 8.67kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77d0c20613cb460cab36aa21501d3665"}},"13b39845cd274e3b900d19c875adc8be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"594a2886e4134b81af747527f97e8c6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b25094cbb91462a9bac17a230c314b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"77d0c20613cb460cab36aa21501d3665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98cac373a28f4164a23bc6a4e0d4d071":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5d36c68389f849b4a27ce77a27acc4a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f6e742d55c5458094913e5ecdef9172","IPY_MODEL_6a6374c9a2f64853af6004a571b7ac57"]}},"5d36c68389f849b4a27ce77a27acc4a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f6e742d55c5458094913e5ecdef9172":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_58a85c24397143f3b78e7cd5e252b398","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1199,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1199,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54362e85c11e40fabc04faee8581c229"}},"6a6374c9a2f64853af6004a571b7ac57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_42a0fe5c638a4c5d97cddb419239bd02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20k/1.20k [00:00&lt;00:00, 33.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_137a55f4e7cb4bc28f17d100120773d6"}},"58a85c24397143f3b78e7cd5e252b398":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"54362e85c11e40fabc04faee8581c229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42a0fe5c638a4c5d97cddb419239bd02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"137a55f4e7cb4bc28f17d100120773d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2882ae4f59524791808682023922a40a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe86416470724cc787138867cdeb4473","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d586cbd3dbff44689c2f8ad4ce29b436","IPY_MODEL_d4becb55858a44479e6ce2be47de76d7"]}},"fe86416470724cc787138867cdeb4473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d586cbd3dbff44689c2f8ad4ce29b436":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a0c1367a7a9b48d6968af5605a0e0c89","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":891691430,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":891691430,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10aabb4148f048ebbfd9e93a63910e36"}},"d4becb55858a44479e6ce2be47de76d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_879c339853fe4f0ba37f2fc3e16bb5d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 892M/892M [00:16&lt;00:00, 55.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60b2bd7859e2476a8ad738c5f015f765"}},"a0c1367a7a9b48d6968af5605a0e0c89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"10aabb4148f048ebbfd9e93a63910e36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"879c339853fe4f0ba37f2fc3e16bb5d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60b2bd7859e2476a8ad738c5f015f765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"dJBUxYvo3Gry"},"source":["# Using a Huggingface T5 model to generate product names from longer descriptions\n","\n","In this notebook we use the text summarization capabilities of the T5 model to generate product names from a longer descriptive text. It is not a model for text generation but summarizing a description can be a good approach to that model.\n","\n","We also show how to register the metrics and performance of the model during the training in the Weight&Biases platform. "]},{"cell_type":"markdown","metadata":{"id":"3efUFN6DK0bO"},"source":["## Loading the libraries"]},{"cell_type":"code","metadata":{"id":"sH5hTIHcL5sd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620380230801,"user_tz":-120,"elapsed":16294,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"66ff5e55-a320-4d01-8205-a89d83363bc5"},"source":["!pip install sentencepiece\n","!pip install transformers -q\n","!pip install wandb -q"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 28.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 32.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 35.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 37.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 39.0MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 23.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 21.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 23.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 23.4MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 23.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 23.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 23.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 23.4MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 23.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 23.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 23.4MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n","\u001b[K     |████████████████████████████████| 2.1MB 34.2MB/s \n","\u001b[K     |████████████████████████████████| 901kB 49.8MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 54.1MB/s \n","\u001b[K     |████████████████████████████████| 2.1MB 18.7MB/s \n","\u001b[K     |████████████████████████████████| 163kB 57.5MB/s \n","\u001b[K     |████████████████████████████████| 102kB 14.4MB/s \n","\u001b[K     |████████████████████████████████| 133kB 57.6MB/s \n","\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n","\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YdMwExxTMFFs"},"source":["#Show packages version\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hb5UT4ZcMEeO"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","import os\n","\n","# Importing the T5 modules from huggingface/transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","import wandb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CM2Q9uwoK6zP"},"source":["Selecting the GPU or CPU device "]},{"cell_type":"code","metadata":{"id":"Tq7DZKJwMWGR"},"source":["# # Setting up the device for GPU usage\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gf2YvtoOLA2X"},"source":["## Loading the dataset"]},{"cell_type":"code","metadata":{"id":"PKDqMo4xMb2s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620380409180,"user_tz":-120,"elapsed":37707,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"1e578086-f151-4dd6-c9be-87499f4d07b0"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"04AFT3OQMKm1"},"source":["The variables containing the data folders and filenames, they should be changed when training in another task."]},{"cell_type":"code","metadata":{"id":"IVAMK2HDPbZV"},"source":["#Set the path to the data folder, datafile and output folder and files\n","root_folder = '/content/drive/My Drive/'\n","data_folder = os.path.abspath(os.path.join(root_folder, 'datasets/text_gen_product_names'))\n","model_folder = os.path.abspath(os.path.join(root_folder, 'Projects/text_generation_names/T5Model'))\n","output_folder = os.path.abspath(os.path.join(root_folder, 'Projects/text_generation_names'))\n","# Set the filenames for your input and output datasets\n","test_filename='cl_test_descriptions.csv'\n","datafile= 'product_names_desc_cl_train.csv'\n","outputfile = 'submission.csv'\n","# Set the path to the files\n","datafile_path = os.path.abspath(os.path.join(data_folder,datafile))\n","testfile_path = os.path.abspath(os.path.join(data_folder,test_filename))\n","outputfile_path = os.path.abspath(os.path.join(output_folder,outputfile))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnFiIWZUP3BV"},"source":["# Set random seeds and deterministic pytorch for reproducibility\n","torch.manual_seed(42) # pytorch random seed\n","np.random.seed(42) # numpy random seed\n","torch.backends.cudnn.deterministic = True\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pgINRks4Ngp"},"source":["Load the datafile with the product descriptions and names:"]},{"cell_type":"code","metadata":{"id":"drs9gZ4KQCGz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620380651858,"user_tz":-120,"elapsed":1708,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"8a53ca43-ba7e-4af3-d5bf-6b00526466d2"},"source":["# Load the dataset: sentence in english, sentence in spanish \n","df=pd.read_csv(datafile_path, header=0, usecols=[0,1])\n","print('Num Examples: ',len(df))\n","print('Null Values\\n', df.isna().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Num Examples:  31593\n","Null Values\n"," name           44\n","description     1\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dnjoeux95lYb"},"source":["Remove rows with null values: "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mPurGBz5nKC","executionInfo":{"status":"ok","timestamp":1620380655469,"user_tz":-120,"elapsed":609,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"13a34716-79e4-497a-b167-446b93ddb153"},"source":["df.dropna(inplace=True)\n","print('Num Examples: ',len(df))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Num Examples:  31548\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ztM9rv8D4Vrz"},"source":["Prepare the data and adjust it to be consumed by the T5 model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJSUTCMi4jlJ","executionInfo":{"status":"ok","timestamp":1620380659478,"user_tz":-120,"elapsed":794,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"e9ea2a64-4aa4-4cda-fe0e-51323e12d210"},"source":["# Add the tag summarize to the description column\n","df.description = 'summarize: ' + df.description\n","print(df.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                                name                                        description\n","0  towel with metallic thread border  summarize: towel with border with lines metall...\n","1     technical cargo bermuda shorts  summarize: printed bermuda shorts made technic...\n","2              body shaping bodysuit  summarize: bodysuit with shapewear effect . th...\n","3                     satin camisole  summarize: vneck with thin adjustable straps.h...\n","4   check print puritan collar dress  summarize: puritan collar dress featuring long...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t66UWyR06XFI"},"source":["## Split the data into train and validation dataset"]},{"cell_type":"code","metadata":{"id":"mU1mqgj_QVSZ"},"source":["# Creation of Dataset and Dataloader\n","# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n","train_size = 0.9\n","train_dataset=df.sample(frac=train_size,random_state = 42)\n","val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2ee_3X8RVjE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620381065419,"user_tz":-120,"elapsed":877,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"165af38a-fcb5-415a-8a8b-299c839ccbee"},"source":["#Only for testing and example\n","text = train_dataset.name\n","ctext = train_dataset.description\n","print(text[0])\n","print(ctext[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["women miranda makaroff print\n","summarize: crop with straight neckline adjustable thin straps . featuring woman miranda makaroff print .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P-LgQ_cxF680"},"source":["# Create the Tokenizer for T5 model"]},{"cell_type":"code","metadata":{"id":"XGbqiBICN-fR"},"source":["base_model=\"t5-base\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5kGdkqrRrYH","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["0a62622aa6b9425c9192d7db9570c83a","83e484770be345479cea6ed14e093348","b7c00848532e47ae9deea1160d25b6bc","13e3236cbe504ff0bc1298fca7369f0f","abfa126f7dd84b52a47af9aaf5c1df86","ff734318c8844d1bad3932f87b99fc5e","5cac03a79918426d99e50af1278d6f06","bb16bdea950e4f56bcfe84afb5c30340","095a328a7f7246a2aee1a2a16ed7782b","cfd835ed937940659395e77055a24f2b","551a29dba30245509623446ca4b98bbc","7e29422a019f4670b654f3761ee3c484","13b39845cd274e3b900d19c875adc8be","594a2886e4134b81af747527f97e8c6a","2b25094cbb91462a9bac17a230c314b5","77d0c20613cb460cab36aa21501d3665"]},"executionInfo":{"status":"ok","timestamp":1620381096717,"user_tz":-120,"elapsed":1278,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"a27851dc-7f17-4fb7-e02e-2302ce2edcbf"},"source":["# tokenzier for encoding the text\n","tokenizer = T5Tokenizer.from_pretrained(base_model)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a62622aa6b9425c9192d7db9570c83a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"095a328a7f7246a2aee1a2a16ed7782b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7rOnx6NeSy5F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620381106267,"user_tz":-120,"elapsed":720,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"f2a6404f-f7de-4bc7-f228-ee4d2c87f404"},"source":["print(tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id)\n","print(tokenizer.bos_token, tokenizer.eos_token, tokenizer.pad_token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using bos_token, but it is not set yet.\n"],"name":"stderr"},{"output_type":"stream","text":["None 1 0\n","None </s> <pad>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yCFkdZGAGMdB"},"source":["## Setting the model parameters"]},{"cell_type":"code","metadata":{"id":"oojeQ1K9PzgB"},"source":["TRAIN_BATCH_SIZE = 8    # input batch size for training (default: 64)\n","VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n","TRAIN_EPOCHS = 3        # number of epochs to train (default: 10)\n","VAL_EPOCHS = 1 \n","LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","SEED = 42               # random seed (default: 42)\n","MAX_LEN = 150 #256\n","SUMMARY_LEN = 7 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H59Z-tQKGV1S"},"source":["# Create the Datasets"]},{"cell_type":"code","metadata":{"id":"G6KZBL7UXhsD"},"source":["# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len, generation_only):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.generation_only = generation_only\n","        if not generation_only:\n","            self.text = self.data.name\n","\n","        self.ctext = self.data.description\n","\n","    def __len__(self):\n","        return len(self.ctext)\n","\n","    def __getitem__(self, index):\n","        ctext = str(self.ctext[index])\n","        ctext = ' '.join(ctext.split())\n","\n","        #source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n","        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, padding='max_length', \n","                                                  truncation=True, return_tensors='pt')\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","\n","        output ={\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long)}\n","        # Create the labels \n","        if not self.generation_only: \n","            text = str(self.text[index])\n","            text = ' '.join(text.split())\n","\n","            #target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n","            target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, padding='max_length', \n","                                                      truncation=True, return_tensors='pt')\n","\n","            target_ids = target['input_ids'].squeeze()\n","            target_mask = target['attention_mask'].squeeze()\n","\n","            output['target_ids']=target_ids.to(dtype=torch.long)\n","            output['target_ids_y']=target_ids.to(dtype=torch.long)\n","\n","        return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cpKL73DYivf"},"source":["# Creating the Training and Validation dataset for further creation of Dataloader\n","training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN, False)\n","val_set = CustomDataset(val_dataset, tokenizer, MAX_LEN, SUMMARY_LEN, False)\n","\n","    # Defining the parameters for creation of dataloaders\n","train_params = {\n","        'batch_size': TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","val_params = {\n","        'batch_size': VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n","training_loader = DataLoader(training_set, **train_params)\n","val_loader = DataLoader(val_set, **val_params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hXnIw-vmjd--"},"source":["## Testing the Dataloader"]},{"cell_type":"code","metadata":{"id":"sSp3UEjSZCMr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611999854100,"user_tz":-60,"elapsed":783,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"3fff7c28-3491-43b7-f03a-afe4c1487d8e"},"source":["it = iter(training_loader)\n","batch = next(it)\n","print(batch[\"source_ids\"].shape, batch[\"target_ids\"].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([2, 256]) torch.Size([2, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cFrVupJeNjrC"},"source":["Let's check the shapes of a single sample:"]},{"cell_type":"code","metadata":{"id":"SKnH_glEZUjj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611771776025,"user_tz":-60,"elapsed":611,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"aee7ba9e-dc44-4639-c19d-bf380e607d17"},"source":["y = batch['target_ids'].to(device, dtype = torch.long)\n","y_ids = y[:,:-1].contiguous() # Original\n","#print(batch['target_ids'][:,target_ids > 0])\n","print(y.shape)\n","#print(y_ids[:,y_ids>0])\n","print(y_ids.shape)\n","lm_labels = y[:,1:].clone().detach() # Original\n","lm_labels[y[:,1:] == tokenizer.pad_token_id] = -100 # Original\n","print(lm_labels.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([2, 10])\n","torch.Size([2, 9])\n","torch.Size([2, 9])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z77G9bpKHou7"},"source":["# Create the T5 model"]},{"cell_type":"code","metadata":{"id":"IznPlGupHjkf","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["98cac373a28f4164a23bc6a4e0d4d071","5d36c68389f849b4a27ce77a27acc4a7","9f6e742d55c5458094913e5ecdef9172","6a6374c9a2f64853af6004a571b7ac57","58a85c24397143f3b78e7cd5e252b398","54362e85c11e40fabc04faee8581c229","42a0fe5c638a4c5d97cddb419239bd02","137a55f4e7cb4bc28f17d100120773d6","2882ae4f59524791808682023922a40a","fe86416470724cc787138867cdeb4473","d586cbd3dbff44689c2f8ad4ce29b436","d4becb55858a44479e6ce2be47de76d7","a0c1367a7a9b48d6968af5605a0e0c89","10aabb4148f048ebbfd9e93a63910e36","879c339853fe4f0ba37f2fc3e16bb5d3","60b2bd7859e2476a8ad738c5f015f765"]},"executionInfo":{"status":"ok","timestamp":1620381290265,"user_tz":-120,"elapsed":33926,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"22b2d084-b24c-425c-e127-2a34e2c1647f"},"source":["# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n","# Further this model is sent to device (GPU/TPU) for using the hardware.\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n","model = model.to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98cac373a28f4164a23bc6a4e0d4d071","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2882ae4f59524791808682023922a40a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O0-xmhleH9ef"},"source":["# Create the train function"]},{"cell_type":"code","metadata":{"id":"78-TCCmcHwec"},"source":["# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n","# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n","def train(epoch, tokenizer, model, device, loader, optimizer):\n","    model.train()\n","    for _,data in enumerate(loader, 0):\n","        y = data['target_ids'].to(device, dtype = torch.long)\n","        y_ids = y[:, :-1].contiguous()\n","        lm_labels = y[:, 1:].clone().detach()\n","        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","        ids = data['source_ids'].to(device, dtype = torch.long)\n","        mask = data['source_mask'].to(device, dtype = torch.long)\n","        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n","        loss = outputs[0]\n","        # Register loss in W&B\n","        #if _%100 == 0:\n","        #    wandb.log({\"Training Loss\": loss.item()})\n","\n","        if _%500==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rrC-iMStIlb5"},"source":["# Create the validation function"]},{"cell_type":"code","metadata":{"id":"qBRdpMBAIjL_"},"source":["# Validation function. After training we apply the model to the test dataset to produce summaries. \n","# We apply a beam search strategy\n","def validate(epoch, tokenizer, model, device, loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=SUMMARY_LEN, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True\n","                )\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            predictions.extend(preds)\n","            actuals.extend(target)\n","    return predictions, actuals"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iNU45fqCJNEu"},"source":["# Training the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FyrImuACJMBF","executionInfo":{"status":"ok","timestamp":1620384976417,"user_tz":-120,"elapsed":35360,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"c5b9185d-1c20-453b-a919-665209b74d68"},"source":["# Defining the optimizer that will be used to tune the weights of the network in the training session. \n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n","\n","# Log metrics with wandb\n","#wandb.watch(model, log=\"all\")\n","# Training loop\n","print('Initiating Fine-Tuning for the model on our dataset')\n","\n","for epoch in range(TRAIN_EPOCHS):\n","        train(epoch, tokenizer, model, device, training_loader, optimizer)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Initiating Fine-Tuning for the model on our dataset\n","Epoch: 0, Loss:  8.945070266723633\n","Epoch: 0, Loss:  2.5906875133514404\n","Epoch: 0, Loss:  1.5396645069122314\n","Epoch: 0, Loss:  0.7348856925964355\n","Epoch: 0, Loss:  1.5720382928848267\n","Epoch: 0, Loss:  2.343564033508301\n","Epoch: 0, Loss:  1.3179247379302979\n","Epoch: 0, Loss:  0.8092208504676819\n","Epoch: 1, Loss:  1.729297161102295\n","Epoch: 1, Loss:  0.840223491191864\n","Epoch: 1, Loss:  0.779865562915802\n","Epoch: 1, Loss:  1.058944821357727\n","Epoch: 1, Loss:  0.5908939242362976\n","Epoch: 1, Loss:  0.6256150007247925\n","Epoch: 1, Loss:  0.778674840927124\n","Epoch: 1, Loss:  0.8843976855278015\n","Epoch: 2, Loss:  0.8240967988967896\n","Epoch: 2, Loss:  0.9908113479614258\n","Epoch: 2, Loss:  0.6734641194343567\n","Epoch: 2, Loss:  1.1316100358963013\n","Epoch: 2, Loss:  0.9343733191490173\n","Epoch: 2, Loss:  1.347994089126587\n","Epoch: 2, Loss:  1.0585122108459473\n","Epoch: 2, Loss:  0.7353636026382446\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eFLHsm_Sw75F"},"source":["## Save the trained model"]},{"cell_type":"code","metadata":{"id":"brX1rwrGw-3G"},"source":["# Save the model\n","model.save_pretrained(model_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FoUtA6xEjvEk"},"source":["# Validate the model with the validation dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4B6WbBzJrOo","executionInfo":{"status":"ok","timestamp":1612211606247,"user_tz":-60,"elapsed":296724,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"6f86f9d1-422f-4f2e-ac24-ac92f81f870a"},"source":["# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n","# Saving the dataframe as predictions.csv\n","print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n","for epoch in range(VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","    final_df.to_csv(outputfile_path)\n","    print('Output Files generated for review')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n","Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Completed 400\n","Completed 500\n","Completed 600\n","Completed 700\n","Completed 800\n","Completed 900\n","Completed 1000\n","Completed 1100\n","Completed 1200\n","Completed 1300\n","Completed 1400\n","Completed 1500\n","Output Files generated for review\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DPAXKfIQuhav"},"source":["# Test the model \n","\n","Once, we are happy with the results on the validation dataset, we can test the model on the test dataset, making prediction applying a beam search strategy."]},{"cell_type":"markdown","metadata":{"id":"S3Sbh696rw9L"},"source":["## Load the trained model\n","\n","If it is neccessary we can load the model saved previously."]},{"cell_type":"code","metadata":{"id":"Mloeo8fjrsgT"},"source":["# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n","# Further this model is sent to device (GPU/TPU) for using the hardware.\n","model = T5ForConditionalGeneration.from_pretrained(model_folder)\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"li9t1Z6KV9CE"},"source":["## Load the test dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":271},"id":"aWAnW4MTg0mr","executionInfo":{"status":"ok","timestamp":1612211926629,"user_tz":-60,"elapsed":1076,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"8af6e39e-a617-4b11-dfe0-cbf937a1776e"},"source":["# Load the dataset: sentence in english, sentence in spanish \n","df=pd.read_csv(testfile_path, header=0)\n","print('Num Examples: ',len(df))\n","print('Null Values\\n', df.isna().sum())\n","df.head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Num Examples:  1441\n","Null Values\n"," description    0\n","dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>knit midi dress with vneckline straps matching...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>loosefitting dress with round neckline long sl...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nautical with peak.this item must returned wit...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nautical with peak . adjustable inner strap de...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nautical with side button detail.this item mus...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         description\n","0  knit midi dress with vneckline straps matching...\n","1  loosefitting dress with round neckline long sl...\n","2  nautical with peak.this item must returned wit...\n","3  nautical with peak . adjustable inner strap de...\n","4  nautical with side button detail.this item mus..."]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"OOZAWg27WB_7"},"source":["Prepare the data for inference, we just need to append the prefix `summarize:` at the beginning of the text."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fw-KWid5u4b5","executionInfo":{"status":"ok","timestamp":1612211936817,"user_tz":-60,"elapsed":488,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"b48c49c6-4235-46a5-95b2-93ffa0083b6b"},"source":["# Add the tag summarize to the description column\n","df.description = 'summarize: ' + df.description\n","print(df.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                                         description\n","0  summarize: knit midi dress with vneckline stra...\n","1  summarize: loosefitting dress with round neckl...\n","2  summarize: nautical with peak.this item must r...\n","3  summarize: nautical with peak . adjustable inn...\n","4  summarize: nautical with side button detail.th...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D8bk3DtyWVxf"},"source":["Create a Dataset to iterate on the test samples."]},{"cell_type":"code","metadata":{"id":"evpyAn0cvIn8"},"source":["# Creating the Test dataset for further creation of Dataloader\n","test_set = CustomDataset(df, tokenizer, MAX_LEN, SUMMARY_LEN, True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"octwvk_xywDi"},"source":["test_params = {\n","        'batch_size': VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","# Creation of Dataloader for testing.\n","test_loader = DataLoader(test_set, **test_params)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdzY0v6Wxt7g","executionInfo":{"status":"ok","timestamp":1612026403504,"user_tz":-60,"elapsed":660,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"3f37718e-ade2-43f7-88db-6a86795f6c5c"},"source":["it = iter(test_loader)\n","batch = next(it)\n","print(batch[\"source_ids\"].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([2, 256])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5I1-wp3uWdM0"},"source":["Invoke the `generate` method using beam search and return 3 alternative summaries. Here we show the results from an example taken from the test dataset. "]},{"cell_type":"code","metadata":{"id":"b2ipKYb5D9Ih"},"source":["ids = batch['source_ids'].to(device, dtype = torch.long)\n","mask = batch['source_mask'].to(device, dtype = torch.long)\n","\n","generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=SUMMARY_LEN, \n","                num_beams=3,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                num_return_sequences = 3,\n","                early_stopping=True\n","                )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkYPCpziQ0dZ","executionInfo":{"status":"ok","timestamp":1612029518166,"user_tz":-60,"elapsed":658,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"a53e11bb-d186-4802-87ec-f629873232e3"},"source":["print(generated_ids.shape)\n","num_outputs=3\n","generated_ids = generated_ids.view(-1, num_outputs,generated_ids.shape[1])\n","print(generated_ids.shape)\n","print(generated_ids)\n","predictions = []\n","for batch_gid in generated_ids:\n","    preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in batch_gid]\n","    preds=','.join(list(filter(None, preds)))\n","    predictions.append(preds)\n","print(predictions)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([6, 7])\n","torch.Size([2, 3, 7])\n","tensor([[[    0,     3, 11706,  3270,     1,     0,     0],\n","         [    0,  3270,    28,     3, 11706,  2736,     1],\n","         [    0,     1,     0,     0,     0,     0,     0]],\n","\n","        [[    0, 32099,     3, 16091,  3270,     1,     0],\n","         [    0, 32099,     3, 24698,  3270,     1,     0],\n","         [    0, 32099,  3270,     1,     0,     0,     0]]], device='cuda:0')\n","['lace dress,dress with lace detail', 'midi dress,oversized dress,dress']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ffu8_IK9U2Uh","executionInfo":{"status":"ok","timestamp":1612029457743,"user_tz":-60,"elapsed":756,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"374a7aab-8fa1-4d4a-804e-ab6e9bfa9fb2"},"source":["l=['lace dress', 'dress with lace detail', '']\n","l=list(filter(None, l))\n","print(l)\n","line=','.join(l)\n","print(line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['lace dress', 'dress with lace detail']\n","lace dress,dress with lace detail\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"onl-jftKkSaq"},"source":["# Create functions for text generation\n","\n","For testing purpouses, we create a function using beam search strategy to produce the output text and another function where "]},{"cell_type":"code","metadata":{"id":"PytAATx9vgDG"},"source":["# Beam  search strategy\n","def generate_beamsearch(tokenizer, model, device, loader, n_beams, rep_penalty, len_penalty, num_outputs):\n","    model.eval()\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            #y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=SUMMARY_LEN, \n","                num_beams=n_beams,\n","                repetition_penalty=rep_penalty, \n","                length_penalty=len_penalty, \n","                num_return_sequences = num_outputs,\n","                early_stopping=True\n","                )\n","            # Reshape hte out to batch_size, num_outputs, len\n","            generated_ids = generated_ids.view(-1, num_outputs,generated_ids.shape[1])\n","            #preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            for batch_gid in generated_ids:\n","                preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in batch_gid]\n","                preds=','.join(list(filter(None, preds)))\n","                predictions.append(preds)\n","\n","            #target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            #predictions.append(preds)\n","            #actuals.extend(target)\n","    return predictions\n","\n","# K sampling strategy\n","def generate_ksampling(tokenizer, model, device, loader, top_k, top_p, rep_penalty, len_penalty, num_outputs):\n","    model.eval()\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            #y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=SUMMARY_LEN, \n","                do_sample=True,\n","                repetition_penalty=rep_penalty, \n","                length_penalty=len_penalty, \n","                num_return_sequences = num_outputs,\n","                top_k=top_k, \n","                top_p=top_p,\n","                early_stopping=True\n","                )\n","            # Reshape hte out to batch_size, num_outputs, len\n","            generated_ids = generated_ids.view(-1, num_outputs,generated_ids.shape[1])\n","            for batch_gid in generated_ids:\n","                preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in batch_gid]\n","                preds=','.join(list(filter(None, preds)))\n","                predictions.append(preds)\n","\n","            #target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            #predictions.append(preds)\n","            #actuals.extend(target)\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CSlYEW5Mw4PH"},"source":["Finally, we generate the text names for the test dataset and save it in a CSV file."]},{"cell_type":"code","metadata":{"id":"UtvOIpbCvhSW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612212639095,"user_tz":-60,"elapsed":142590,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"948f4a87-36c3-4226-b986-5965cf19dc85"},"source":["# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n","# Saving the dataframe as predictions.csv\n","print('Now generating summaries on our fine tuned model for the test dataset and saving it in a dataframe')\n","#generate_beamsearch(tokenizer, model, device, loader, n_beams, rep_penalty, len_penalty)\n","#predictions = generate_beamsearch(tokenizer, model, device, test_loader, 25, 2.5, 1.0, 1)\n","predictions = generate_ksampling(tokenizer, model, device, test_loader, 50, 0.95, 1.5, 1.0, 3)\n","final_df = pd.DataFrame({'name':predictions})\n","final_df.to_csv(outputfile_path, index=False)\n","print('Output Files generated for review')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Now generating summaries on our fine tuned model for the test dataset and saving it in a dataframe\n","Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Completed 400\n","Completed 500\n","Completed 600\n","Completed 700\n","Output Files generated for review\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lukhCQX-C11","executionInfo":{"status":"ok","timestamp":1612212222759,"user_tz":-60,"elapsed":504,"user":{"displayName":"Eduardo Muñoz Sala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64","userId":"13317831924226771761"}},"outputId":"d60d1857-c838-484c-e618-caaa02e6f401"},"source":["len(predictions)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1441"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"GoBepKLEZHYA"},"source":[""],"execution_count":null,"outputs":[]}]}